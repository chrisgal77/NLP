{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b764e0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:22:59.378610Z",
     "iopub.status.busy": "2023-12-28T21:22:59.378271Z",
     "iopub.status.idle": "2023-12-28T21:23:38.970273Z",
     "shell.execute_reply": "2023-12-28T21:23:38.969451Z"
    },
    "papermill": {
     "duration": 39.602311,
     "end_time": "2023-12-28T21:23:38.972641",
     "exception": false,
     "start_time": "2023-12-28T21:22:59.370330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\r\n",
      "  Obtaining dependency information for lightning from https://files.pythonhosted.org/packages/8c/a1/b2a6c33675510bc3e1ca6d010b244ac0dd9c81fc1723a37e7491aa586041/lightning-2.1.3-py3-none-any.whl.metadata\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading lightning-2.1.3-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.12.2)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.10.0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.24.3)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.1)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.5.0)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.4)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.8.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (68.1.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.0.9)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2023.11.17)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading lightning-2.1.3-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: lightning\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed lightning-2.1.3\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning gensim torch\n",
    "\n",
    "from time import perf_counter\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
    "import torch.optim as optim\n",
    "from lightning.pytorch.callbacks import TQDMProgressBar, ModelCheckpoint\n",
    "from lightning.pytorch.loggers.tensorboard import TensorBoardLogger\n",
    "from gensim.models import KeyedVectors\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from lightning.pytorch.tuner import Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba24a84",
   "metadata": {
    "papermill": {
     "duration": 0.007112,
     "end_time": "2023-12-28T21:23:38.987860",
     "exception": false,
     "start_time": "2023-12-28T21:23:38.980748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a919ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:23:39.004066Z",
     "iopub.status.busy": "2023-12-28T21:23:39.003544Z",
     "iopub.status.idle": "2023-12-28T21:23:39.008266Z",
     "shell.execute_reply": "2023-12-28T21:23:39.007551Z"
    },
    "papermill": {
     "duration": 0.015048,
     "end_time": "2023-12-28T21:23:39.010121",
     "exception": false,
     "start_time": "2023-12-28T21:23:38.995073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def measure_time() -> float:\n",
    "    start = perf_counter()\n",
    "    yield lambda: perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dfc234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:23:39.025828Z",
     "iopub.status.busy": "2023-12-28T21:23:39.025553Z",
     "iopub.status.idle": "2023-12-28T21:23:39.029693Z",
     "shell.execute_reply": "2023-12-28T21:23:39.028849Z"
    },
    "papermill": {
     "duration": 0.014137,
     "end_time": "2023-12-28T21:23:39.031506",
     "exception": false,
     "start_time": "2023-12-28T21:23:39.017369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "POLISH_TRANSFORMER_MODEL_NAME = \"dkleczek/bert-base-polish-cased-v1\"\n",
    "DATA_PATH = Path(\"/kaggle/input/poleval\")\n",
    "CWD_PATH = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf580ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:23:39.047170Z",
     "iopub.status.busy": "2023-12-28T21:23:39.046922Z",
     "iopub.status.idle": "2023-12-28T21:24:00.967725Z",
     "shell.execute_reply": "2023-12-28T21:24:00.966450Z"
    },
    "papermill": {
     "duration": 21.931301,
     "end_time": "2023-12-28T21:24:00.970116",
     "exception": false,
     "start_time": "2023-12-28T21:23:39.038815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-28 21:23:39--  https://github.com/sdadas/polish-nlp-resources/releases/download/v1.0/glove.zip\r\n",
      "Resolving github.com (github.com)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.82.114.4\r\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/151131563/b3ad1180-acb6-11e9-83f1-dcfed2e65aca?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20231228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231228T212340Z&X-Amz-Expires=300&X-Amz-Signature=e3124c9c16fc4112786adc9e34534a0ba353760c44100d886435043ee03a9895&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=151131563&response-content-disposition=attachment%3B%20filename%3Dglove.zip&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2023-12-28 21:23:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/151131563/b3ad1180-acb6-11e9-83f1-dcfed2e65aca?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20231228%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231228T212340Z&X-Amz-Expires=300&X-Amz-Signature=e3124c9c16fc4112786adc9e34534a0ba353760c44100d886435043ee03a9895&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=151131563&response-content-disposition=attachment%3B%20filename%3Dglove.zip&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\r\n",
      "Length: 656379892 (626M) [application/octet-stream]\r\n",
      "Saving to: 'glove.zip'\r\n",
      "\r\n",
      "\r\n",
      "glove.zip             0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip             4%[                    ]  25.41M   127MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            11%[=>                  ]  73.65M   184MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            22%[===>                ] 140.32M   234MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            30%[=====>              ] 191.04M   235MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            40%[=======>            ] 252.61M   249MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            47%[========>           ] 299.44M   247MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            56%[==========>         ] 353.99M   250MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            65%[============>       ] 409.11M   254MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            74%[=============>      ] 463.81M   256MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            79%[==============>     ] 500.74M   249MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            86%[================>   ] 540.23M   244MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            89%[================>   ] 560.89M   231MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            92%[=================>  ] 577.68M   220MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip            98%[==================> ] 614.74M   217MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "glove.zip           100%[===================>] 625.97M   217MB/s    in 2.9s    \r\n",
      "\r\n",
      "2023-12-28 21:23:43 (217 MB/s) - 'glove.zip' saved [656379892/656379892]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /kaggle/working/glove.zip\r\n",
      "  inflating: glove_100_3_polish.txt  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/sdadas/polish-nlp-resources/releases/download/v1.0/glove.zip\n",
    "!unzip /kaggle/working/glove.zip\n",
    "!rm /kaggle/working/glove.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df56b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:24:00.990385Z",
     "iopub.status.busy": "2023-12-28T21:24:00.990048Z",
     "iopub.status.idle": "2023-12-28T21:24:01.002175Z",
     "shell.execute_reply": "2023-12-28T21:24:01.001262Z"
    },
    "papermill": {
     "duration": 0.02462,
     "end_time": "2023-12-28T21:24:01.004236",
     "exception": false,
     "start_time": "2023-12-28T21:24:00.979616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, model_name: str = POLISH_TRANSFORMER_MODEL_NAME, start_training_layer: int = -1, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model, model_out_channels = self._get_transformer(model_name=model_name, start_training_layer=start_training_layer)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=model_out_channels, out_features=1024),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=1024, out_features=num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        pooler_output = self.model(input_ids, attention_mask=attention_mask)[\"pooler_output\"]\n",
    "\n",
    "        return self.classifier(pooler_output)\n",
    "    \n",
    "    def _get_transformer(self, model_name: str, start_training_layer: int):\n",
    "        \"\"\"Get pretrained Transformer model.\n",
    "\n",
    "        Args:\n",
    "            start_training_layer (int): Get number of layer from which model will be unfrozen. Pass -1 if unfreeze none of them.\n",
    "        \"\"\"\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        if start_training_layer == -1:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            return model, model.pooler.dense.out_features\n",
    "\n",
    "        start_training_index = start_training_layer * 16\n",
    "\n",
    "        for param in model.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for idx, param in enumerate(model.encoder.layer.parameters()):\n",
    "            param.requires_grad = False if idx < start_training_index else True\n",
    "\n",
    "        for param in model.pooler.parameters():\n",
    "            param.requires_grad = True if start_training_layer != -1 else False\n",
    "\n",
    "        return model, model.pooler.dense.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5101d821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:24:01.024217Z",
     "iopub.status.busy": "2023-12-28T21:24:01.023885Z",
     "iopub.status.idle": "2023-12-28T21:24:01.035132Z",
     "shell.execute_reply": "2023-12-28T21:24:01.034221Z"
    },
    "papermill": {
     "duration": 0.023485,
     "end_time": "2023-12-28T21:24:01.037038",
     "exception": false,
     "start_time": "2023-12-28T21:24:01.013553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransfromerDataset(Dataset):\n",
    "    def __init__(self, data_df: pd.DataFrame, target_column: str, text_column: str, model_name: str = POLISH_TRANSFORMER_MODEL_NAME):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data, self.target = self._prepare_data_to_transformer(\n",
    "            data_df=data_df,\n",
    "            target_column=target_column,\n",
    "            text_column=text_column,\n",
    "            model_name=model_name\n",
    "        )\n",
    "\n",
    "        self.class_mapping = {\n",
    "            class_name: idx for idx, class_name in enumerate((np.unique(self.target)))\n",
    "        }\n",
    "\n",
    "        self.num_classes = max(list(self.class_mapping.values())) + 1\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        sample_data_input_id = torch.tensor(self.data[\"input_ids\"][index])\n",
    "        sample_data_attention_mask = torch.tensor(self.data[\"attention_mask\"][index])\n",
    "        sample_target = F.one_hot(\n",
    "            torch.tensor(self.class_mapping[self.target[index]]), num_classes=self.num_classes\n",
    "        ).float()\n",
    "\n",
    "        return sample_data_input_id, sample_data_attention_mask, sample_target\n",
    "    \n",
    "    def _prepare_data_to_transformer(\n",
    "        self, data_df: pd.DataFrame, target_column: str, text_column: str, model_name: str = POLISH_TRANSFORMER_MODEL_NAME\n",
    "    ):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        data = tokenizer.batch_encode_plus(\n",
    "            data_df[text_column].tolist(),\n",
    "            max_length = 512,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        target = data_df[target_column].tolist()\n",
    "\n",
    "        return data, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.target)\n",
    "    \n",
    "    def get_labels(self) -> list[int]:\n",
    "        return [self.class_mapping[label] for label in self.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0cef61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:24:01.056853Z",
     "iopub.status.busy": "2023-12-28T21:24:01.056543Z",
     "iopub.status.idle": "2023-12-28T21:24:01.065668Z",
     "shell.execute_reply": "2023-12-28T21:24:01.064805Z"
    },
    "papermill": {
     "duration": 0.021244,
     "end_time": "2023-12-28T21:24:01.067514",
     "exception": false,
     "start_time": "2023-12-28T21:24:01.046270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDatasetModule(L.LightningDataModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        self.train = TransfromerDataset(\n",
    "            data_df=pd.read_csv(self.hparams.data_root / \"train.csv\"),\n",
    "            target_column=self.hparams.target_column,\n",
    "            text_column=self.hparams.text_column,\n",
    "            model_name=self.hparams.model_name\n",
    "        )\n",
    "        self.test = TransfromerDataset(\n",
    "            data_df=pd.read_csv(self.hparams.data_root / \"test.csv\"),\n",
    "            target_column=self.hparams.target_column,\n",
    "            text_column=self.hparams.text_column,\n",
    "            model_name=self.hparams.model_name\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.hparams.batch_size, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.hparams.batch_size, shuffle=False)\n",
    "    \n",
    "    def get_class_weights(self) -> list[float]:\n",
    "        labels = self.train.get_labels()\n",
    "        return torch.tensor(compute_class_weight('balanced', classes=np.unique(labels), y=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad89fee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:24:01.087302Z",
     "iopub.status.busy": "2023-12-28T21:24:01.087025Z",
     "iopub.status.idle": "2023-12-28T21:24:01.101545Z",
     "shell.execute_reply": "2023-12-28T21:24:01.100707Z"
    },
    "papermill": {
     "duration": 0.026912,
     "end_time": "2023-12-28T21:24:01.103550",
     "exception": false,
     "start_time": "2023-12-28T21:24:01.076638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerModule(L.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = TransformerWrapper(\n",
    "            model_name=self.hparams.model_name,\n",
    "            start_training_layer=self.hparams.start_training_layer,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        metrics = MetricCollection([\n",
    "            MulticlassAccuracy(self.hparams.num_classes, average=None),\n",
    "            MulticlassPrecision(self.hparams.num_classes, average=None),\n",
    "            MulticlassRecall(self.hparams.num_classes, average=None),\n",
    "            MulticlassF1Score(self.hparams.num_classes, average=None)\n",
    "        ])\n",
    "        self.metrics = {\n",
    "            \"train\": metrics.clone(prefix='train_'),\n",
    "            \"test\": metrics.clone(prefix='test_')\n",
    "        }\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=self.hparams.class_weights)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        return self.model(input_ids, attention_mask)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._shared_eval(batch, batch_idx, \"train\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_eval(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx, stage):\n",
    "        input_ids, attention_mask, targets = batch\n",
    "        logits = self(input_ids, attention_mask)\n",
    "\n",
    "        loss = self.criterion(logits, targets)\n",
    "\n",
    "        self.metrics[stage].update(torch.argmax(logits, -1).detach().cpu(), torch.argmax(targets, -1).detach().cpu())\n",
    "\n",
    "        self.log(f\"{stage}_loss\", loss.detach().cpu(), on_epoch=True, on_step=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        metrics = self.metrics[\"train\"].compute()\n",
    "\n",
    "        for metric_name, values in metrics.items():\n",
    "            for idx, value in enumerate(values):\n",
    "                self.log(f\"{metric_name}_class_{idx}\", value, on_epoch=True)\n",
    "\n",
    "        self.metrics[\"train\"].reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        metrics = self.metrics[\"test\"].compute()\n",
    "\n",
    "        for metric_name, values in metrics.items():\n",
    "            for idx, value in enumerate(values):\n",
    "                self.log(f\"{metric_name}_class_{idx}\", value, on_epoch=True)\n",
    "\n",
    "        self.metrics[\"test\"].reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.97)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edb0b3",
   "metadata": {
    "papermill": {
     "duration": 0.008795,
     "end_time": "2023-12-28T21:24:01.121865",
     "exception": false,
     "start_time": "2023-12-28T21:24:01.113070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformer Training\n",
    "\n",
    "## Setup\n",
    "- only classification head\n",
    "- unfreeze last encoder layer + classification head\n",
    "- unfreeze last 2 encoder layers + classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b954fa59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T21:24:01.141031Z",
     "iopub.status.busy": "2023-12-28T21:24:01.140729Z",
     "iopub.status.idle": "2023-12-29T08:29:03.261028Z",
     "shell.execute_reply": "2023-12-29T08:29:03.260240Z"
    },
    "papermill": {
     "duration": 39902.132501,
     "end_time": "2023-12-29T08:29:03.263308",
     "exception": false,
     "start_time": "2023-12-28T21:24:01.130807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9c78e5f2df4fe8aa0849bbf2adf994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a63cad79a804e58a18e5371756dbf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc022776fd244e08029664f3e5fb8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/489k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4779db7ae464602a2578d2e9db25a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95a054cc2bf479fa52fe52dc8bc1725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/531M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Missing logger folder: logs/lightning_logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e61f07e7524c61a2c3206e2ed762aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LR finder stopped early after 91 steps due to diverging loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Learning rate set to 0.09120108393559097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restoring states from the checkpoint path at /kaggle/working/.lr_find_83f20473-2ca6-4862-9c83-71aebc98ade1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restored all states from the checkpoint at /kaggle/working/.lr_find_83f20473-2ca6-4862-9c83-71aebc98ade1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | TransformerWrapper | 132 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "-------------------------------------------------\n",
      "789 K     Trainable params\n",
      "132 M     Non-trainable params\n",
      "132 M     Total params\n",
      "531.643   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c02ff12b30f4095be9a08a5601efb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990d8ae051eb406fb43f17b289acd721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">           Test metric            </span>┃<span style=\"font-weight: bold\">           DataLoader 0           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.09570419043302536        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9411764740943909        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.1738271564245224        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.1605619639158249        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_0 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9462365508079529        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.08776741474866867        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_0   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.09570419043302536        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_1   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9411764740943909        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss_epoch          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        1.0136906459580663        </span>│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m          Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.09570419043302536       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9411764740943909       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.1738271564245224       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.1605619639158249       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_0\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9462365508079529       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.08776741474866867       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_0  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.09570419043302536       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_1  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9411764740943909       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       1.0136906459580663       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4dd9ff688a74ed8891cda87e6af3b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LR finder stopped early after 80 steps due to diverging loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Learning rate set to 3.311311214825911e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restoring states from the checkpoint path at /kaggle/working/.lr_find_fd8f04ae-89f2-4e6a-bd5b-0d59a23f58cb.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restored all states from the checkpoint at /kaggle/working/.lr_find_fd8f04ae-89f2-4e6a-bd5b-0d59a23f58cb.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | TransformerWrapper | 132 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "-------------------------------------------------\n",
      "29.7 M    Trainable params\n",
      "103 M     Non-trainable params\n",
      "132 M     Total params\n",
      "531.643   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c27a9114fa41d4a23675d3d0a407eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb66ec578f774e819657ad0930ffa083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">           Test metric            </span>┃<span style=\"font-weight: bold\">           DataLoader 0           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9700924158096313        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.570588231086731         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9653679728507996        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.6024844646453857        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_0 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9606893062591553        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.6381579041481018        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_0   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9700924158096313        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_1   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.570588231086731         </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss_epoch          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        1.9250344743401195        </span>│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m          Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9700924158096313       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.570588231086731        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9653679728507996       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.6024844646453857       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_0\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9606893062591553       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.6381579041481018       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_0  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9700924158096313       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_1  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.570588231086731        \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       1.9250344743401195       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a4946d5c784cc889ce3caa7cea8a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LR finder stopped early after 76 steps due to diverging loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Learning rate set to 0.001584893192461114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restoring states from the checkpoint path at /kaggle/working/.lr_find_3d3aa8f3-d3cd-4676-b9a1-e32fa7cc7899.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restored all states from the checkpoint at /kaggle/working/.lr_find_3d3aa8f3-d3cd-4676-b9a1-e32fa7cc7899.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | TransformerWrapper | 132 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "-------------------------------------------------\n",
      "22.6 M    Trainable params\n",
      "110 M     Non-trainable params\n",
      "132 M     Total params\n",
      "531.643   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41507c02b0cc454f8df50ea20269c4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65c1893a192494f9ebfe8eb0939d5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">           Test metric            </span>┃<span style=\"font-weight: bold\">           DataLoader 0           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">               0.0                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">               1.0                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">               0.0                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.15603487193584442        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_0 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">               0.0                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.08461921662092209        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_0   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">               0.0                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_1   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">               1.0                </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss_epoch          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.6925301757305179        </span>│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m          Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m              0.0               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m              1.0               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m              0.0               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.15603487193584442       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_0\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m              0.0               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.08461921662092209       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_0  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m              0.0               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_1  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m              1.0               \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.6925301757305179       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2423af13a94e3186463d4faa109864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LR finder stopped early after 76 steps due to diverging loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Learning rate set to 4.365158322401661e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restoring states from the checkpoint path at /kaggle/working/.lr_find_a6b16f69-9ef6-491b-8455-c048cc8f5825.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restored all states from the checkpoint at /kaggle/working/.lr_find_a6b16f69-9ef6-491b-8455-c048cc8f5825.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | TransformerWrapper | 132 M \n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "-------------------------------------------------\n",
      "15.6 M    Trainable params\n",
      "117 M     Non-trainable params\n",
      "132 M     Total params\n",
      "531.643   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7693f3b2f1034358a83997dced71538e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de25a118090f437989ca2830c9e74148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">           Test metric            </span>┃<span style=\"font-weight: bold\">           DataLoader 0           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.8983142971992493        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.7588235139846802        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9354473352432251        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.5308641791343689        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_0 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9757826328277588        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.4082278609275818        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_0   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.8983142971992493        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_1   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.7588235139846802        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss_epoch          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.5901837644620981        </span>│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m          Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.8983142971992493       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.7588235139846802       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9354473352432251       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.5308641791343689       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_0\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9757826328277588       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.4082278609275818       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_0  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.8983142971992493       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_1  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.7588235139846802       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.5901837644620981       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer_scores = {}\n",
    "\n",
    "for start_training_layer in [-1, 8, 9, 10]:\n",
    "    datamodule = TransformerDatasetModule(\n",
    "        target_column=\"label\",\n",
    "        text_column=\"preprocessed_text\",\n",
    "        batch_size=64,\n",
    "        model_name=POLISH_TRANSFORMER_MODEL_NAME,\n",
    "        data_root=DATA_PATH\n",
    "    )\n",
    "    datamodule.setup()\n",
    "\n",
    "    model = TransformerModule(\n",
    "        model_name=POLISH_TRANSFORMER_MODEL_NAME,\n",
    "        num_classes=2,\n",
    "        start_training_layer=start_training_layer,\n",
    "        lr=2e-5,\n",
    "        class_weights=datamodule.get_class_weights()\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=50,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=\"auto\",\n",
    "        callbacks=[TQDMProgressBar(refresh_rate=2), ModelCheckpoint(\n",
    "            dirpath=\"checkpoints/\",\n",
    "            filename=\"{epoch}-{train_loss:.2f}\",\n",
    "            mode=\"min\",\n",
    "            monitor='train_loss',\n",
    "            \n",
    "        )],\n",
    "        logger=TensorBoardLogger(save_dir=\"logs/\"),\n",
    "        log_every_n_steps=2,\n",
    "    )\n",
    "\n",
    "    tuner = Tuner(trainer)\n",
    "\n",
    "    tuner.lr_find(\n",
    "        model=model,\n",
    "        datamodule=datamodule,\n",
    "        method=\"fit\"\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    \n",
    "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "    best_model = TransformerModule.load_from_checkpoint(best_model_path)\n",
    "    \n",
    "    transformer_test_scores = trainer.test(best_model, datamodule=datamodule)\n",
    "\n",
    "    transformer_scores[start_training_layer] = transformer_test_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a06c8464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T08:29:03.301428Z",
     "iopub.status.busy": "2023-12-29T08:29:03.300705Z",
     "iopub.status.idle": "2023-12-29T08:29:03.319957Z",
     "shell.execute_reply": "2023-12-29T08:29:03.319056Z"
    },
    "papermill": {
     "duration": 0.040308,
     "end_time": "2023-12-29T08:29:03.321826",
     "exception": false,
     "start_time": "2023-12-29T08:29:03.281518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_loss_epoch</th>\n",
       "      <td>1.013691</td>\n",
       "      <td>1.925034</td>\n",
       "      <td>0.692530</td>\n",
       "      <td>0.590184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassAccuracy_class_0</th>\n",
       "      <td>0.095704</td>\n",
       "      <td>0.970092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.898314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassAccuracy_class_1</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.570588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassPrecision_class_0</th>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.960689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassPrecision_class_1</th>\n",
       "      <td>0.087767</td>\n",
       "      <td>0.638158</td>\n",
       "      <td>0.084619</td>\n",
       "      <td>0.408228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassRecall_class_0</th>\n",
       "      <td>0.095704</td>\n",
       "      <td>0.970092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.898314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassRecall_class_1</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.570588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassF1Score_class_0</th>\n",
       "      <td>0.173827</td>\n",
       "      <td>0.965368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MulticlassF1Score_class_1</th>\n",
       "      <td>0.160562</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>0.156035</td>\n",
       "      <td>0.530864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       -1         8         9         10\n",
       "test_loss_epoch                   1.013691  1.925034  0.692530  0.590184\n",
       "test_MulticlassAccuracy_class_0   0.095704  0.970092  0.000000  0.898314\n",
       "test_MulticlassAccuracy_class_1   0.941176  0.570588  1.000000  0.758824\n",
       "test_MulticlassPrecision_class_0  0.946237  0.960689  0.000000  0.975783\n",
       "test_MulticlassPrecision_class_1  0.087767  0.638158  0.084619  0.408228\n",
       "test_MulticlassRecall_class_0     0.095704  0.970092  0.000000  0.898314\n",
       "test_MulticlassRecall_class_1     0.941176  0.570588  1.000000  0.758824\n",
       "test_MulticlassF1Score_class_0    0.173827  0.965368  0.000000  0.935447\n",
       "test_MulticlassF1Score_class_1    0.160562  0.602484  0.156035  0.530864"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(transformer_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e8d5d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T08:29:03.366254Z",
     "iopub.status.busy": "2023-12-29T08:29:03.365821Z",
     "iopub.status.idle": "2023-12-29T08:29:03.377156Z",
     "shell.execute_reply": "2023-12-29T08:29:03.375737Z"
    },
    "papermill": {
     "duration": 0.039632,
     "end_time": "2023-12-29T08:29:03.379651",
     "exception": false,
     "start_time": "2023-12-29T08:29:03.340019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Word2VecWrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int = 2, num_layers: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=100, hidden_size=256, batch_first=True, num_layers=num_layers, bidirectional=True, dropout=0.2)\n",
    "\n",
    "        self.fcn = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        _, (last_hidden, _) = self.lstm(sequence)\n",
    "\n",
    "        return self.fcn(last_hidden[-1])\n",
    "    \n",
    "    def _get_word2vec(self, model_path: str):\n",
    "        return KeyedVectors.load_word2vec_format(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290732bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T08:29:03.423842Z",
     "iopub.status.busy": "2023-12-29T08:29:03.423229Z",
     "iopub.status.idle": "2023-12-29T08:29:03.445558Z",
     "shell.execute_reply": "2023-12-29T08:29:03.444480Z"
    },
    "papermill": {
     "duration": 0.045396,
     "end_time": "2023-12-29T08:29:03.447495",
     "exception": false,
     "start_time": "2023-12-29T08:29:03.402099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMModule(L.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = Word2VecWrapper(\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            num_layers=self.hparams.num_layers\n",
    "        )\n",
    "\n",
    "        metrics = MetricCollection([\n",
    "            MulticlassAccuracy(self.hparams.num_classes, average=None),\n",
    "            MulticlassPrecision(self.hparams.num_classes, average=None),\n",
    "            MulticlassRecall(self.hparams.num_classes, average=None),\n",
    "            MulticlassF1Score(self.hparams.num_classes, average=None)\n",
    "        ])\n",
    "        self.metrics = {\n",
    "            \"train\": metrics.clone(prefix='train_'),\n",
    "            \"test\": metrics.clone(prefix='test_')\n",
    "        }\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=self.hparams.class_weights)\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        return self.model(sequence)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._shared_eval(batch, batch_idx, \"train\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_eval(batch, batch_idx, \"test\")\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx, stage):\n",
    "        sequences, targets = batch\n",
    "        batch_size = targets.shape[0]\n",
    "        logits = self(sequences)\n",
    "\n",
    "        loss = self.criterion(logits, targets)\n",
    "\n",
    "        self.metrics[stage].update(torch.argmax(logits, -1).detach().cpu(), torch.argmax(targets, -1).detach().cpu())\n",
    "\n",
    "        self.log(f\"{stage}_loss\", loss.detach().cpu(), on_epoch=True, on_step=True, batch_size=batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        metrics = self.metrics[\"train\"].compute()\n",
    "\n",
    "        for metric_name, values in metrics.items():\n",
    "            for idx, value in enumerate(values):\n",
    "                self.log(f\"{metric_name}_class_{idx}\", value, on_epoch=True)\n",
    "\n",
    "        self.metrics[\"train\"].reset()\n",
    "\n",
    "    def on_test_epoch_end(self) -> None:\n",
    "        metrics = self.metrics[\"test\"].compute()\n",
    "\n",
    "        for metric_name, values in metrics.items():\n",
    "            for idx, value in enumerate(values):\n",
    "                self.log(f\"{metric_name}_class_{idx}\", value, on_epoch=True)\n",
    "\n",
    "        self.metrics[\"test\"].reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.97)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e820bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T08:29:03.485721Z",
     "iopub.status.busy": "2023-12-29T08:29:03.485056Z",
     "iopub.status.idle": "2023-12-29T08:29:03.496607Z",
     "shell.execute_reply": "2023-12-29T08:29:03.495731Z"
    },
    "papermill": {
     "duration": 0.032301,
     "end_time": "2023-12-29T08:29:03.498367",
     "exception": false,
     "start_time": "2023-12-29T08:29:03.466066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, data_df: pd.DataFrame, target_column: str, text_column: str, model_path: str = \"glove_100_3_polish.txt\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.word2vec = KeyedVectors.load_word2vec_format(model_path)\n",
    "\n",
    "        self.data, self.target = self._prepare_data_to_transformer(\n",
    "            data_df=data_df,\n",
    "            target_column=target_column,\n",
    "            text_column=text_column,\n",
    "        )\n",
    "\n",
    "        self.class_mapping = {\n",
    "            class_name: idx for idx, class_name in enumerate((np.unique(self.target)))\n",
    "        }\n",
    "\n",
    "        self.num_classes = max(list(self.class_mapping.values())) + 1\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        sample_data = torch.tensor(self.data[index]).float()\n",
    "\n",
    "        sample_target = F.one_hot(\n",
    "            torch.tensor(self.class_mapping[self.target[index]]), num_classes=self.num_classes\n",
    "        ).float()\n",
    "\n",
    "        return sample_data, sample_target\n",
    "    \n",
    "    def _prepare_data_to_transformer(\n",
    "        self, data_df: pd.DataFrame, target_column: str, text_column: str\n",
    "    ):\n",
    "        data = data_df[text_column].tolist()\n",
    "\n",
    "        data = [\n",
    "            element.split(\" \") for element in data\n",
    "        ]\n",
    "\n",
    "        oov_embedding = np.random.random(self.word2vec.vector_size)\n",
    "\n",
    "        data = [\n",
    "            [\n",
    "                self.word2vec.get_vector(word) if word in self.word2vec.key_to_index else oov_embedding for word  in words\n",
    "            ] for words in data\n",
    "        ]\n",
    "\n",
    "        target = data_df[target_column].tolist()\n",
    "\n",
    "        return data, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.target)\n",
    "    \n",
    "    def get_labels(self) -> list[int]:\n",
    "        return [self.class_mapping[label] for label in self.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcfa6eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T08:29:03.536511Z",
     "iopub.status.busy": "2023-12-29T08:29:03.535867Z",
     "iopub.status.idle": "2023-12-29T08:29:03.546853Z",
     "shell.execute_reply": "2023-12-29T08:29:03.545895Z"
    },
    "papermill": {
     "duration": 0.032264,
     "end_time": "2023-12-29T08:29:03.548781",
     "exception": false,
     "start_time": "2023-12-29T08:29:03.516517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMDatasetModule(L.LightningDataModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        self.train = LSTMDataset(\n",
    "            data_df=pd.read_csv(self.hparams.data_root / \"train.csv\"),\n",
    "            target_column=self.hparams.target_column,\n",
    "            text_column=self.hparams.text_column,\n",
    "        )\n",
    "        self.test = LSTMDataset(\n",
    "            data_df=pd.read_csv(self.hparams.data_root / \"test.csv\"),\n",
    "            target_column=self.hparams.target_column,\n",
    "            text_column=self.hparams.text_column,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.hparams.batch_size, shuffle=True, collate_fn=self._collate_fn)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.hparams.batch_size, shuffle=False, collate_fn=self._collate_fn)\n",
    "    \n",
    "    def _collate_fn(self, batch: list[tuple[torch.Tensor, torch.Tensor]]):\n",
    "        sequences, targets = [seq for seq, _ in batch], [target for _, target in batch]\n",
    "        \n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        \n",
    "        padded_seqs = pad_sequence(sequences, batch_first=True)\n",
    "        \n",
    "        packed_seqs = pack_padded_sequence(padded_seqs, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        return packed_seqs, torch.stack(targets)\n",
    "    \n",
    "    def get_class_weights(self) -> list[float]:\n",
    "        labels = self.train.get_labels()\n",
    "        return torch.tensor(compute_class_weight('balanced', classes=np.unique(labels), y=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb56183a",
   "metadata": {
    "papermill": {
     "duration": 0.017737,
     "end_time": "2023-12-29T08:29:03.584729",
     "exception": false,
     "start_time": "2023-12-29T08:29:03.566992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LSTM Training\n",
    "\n",
    "## Setup\n",
    "- Word embeddings from GloVe + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a416ef7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T08:29:03.621924Z",
     "iopub.status.busy": "2023-12-29T08:29:03.621328Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-12-29T08:29:03.602689",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "/tmp/ipykernel_27/3431073847.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  sample_data = torch.tensor(self.data[index]).float()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2952364f20ba421b8546c08884a2957c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LR finder stopped early after 95 steps due to diverging loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Learning rate set to 0.00017378008287493763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restoring states from the checkpoint path at /kaggle/working/.lr_find_d0807e5f-c7ab-48ac-9a49-a0bd91c3e72e.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restored all states from the checkpoint at /kaggle/working/.lr_find_d0807e5f-c7ab-48ac-9a49-a0bd91c3e72e.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | Word2VecWrapper  | 865 K \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "865 K     Trainable params\n",
      "0         Non-trainable params\n",
      "865 K     Total params\n",
      "3.463     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42621beeb4084cc899910115c72143b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0bddd389e34b95b7ca1f94ae130c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">           Test metric            </span>┃<span style=\"font-weight: bold\">           DataLoader 0           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.24306687712669373        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassAccuracy_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9529411792755127        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_0  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.38971230387687683        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassF1Score_class_1  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.18793503940105438        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_0 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9824175834655762        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassPrecision_class_1 </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.10424710065126419        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_0   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.24306687712669373        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_MulticlassRecall_class_1   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.9529411792755127        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss_epoch          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        1.5490911842520945        </span>│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m          Test metric           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m          DataLoader 0          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.24306687712669373       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassAccuracy_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9529411792755127       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_0 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.38971230387687683       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassF1Score_class_1 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.18793503940105438       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_0\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9824175834655762       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassPrecision_class_1\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.10424710065126419       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_0  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.24306687712669373       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_MulticlassRecall_class_1  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.9529411792755127       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss_epoch         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       1.5490911842520945       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└──────────────────────────────────┴──────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028a1ff7ff97498b8a1abd0ee4969389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LR finder stopped early after 91 steps due to diverging loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Learning rate set to 0.0022908676527677745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restoring states from the checkpoint path at /kaggle/working/.lr_find_7659d74d-9db9-4e23-b1b4-cda6e2c656e7.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Restored all states from the checkpoint at /kaggle/working/.lr_find_7659d74d-9db9-4e23-b1b4-cda6e2c656e7.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory /kaggle/working/checkpoints exists and is not empty.\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | Word2VecWrapper  | 4.0 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.079    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560d0a341b914c6eb48bca464d9d11c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_test_scores = {}\n",
    "\n",
    "for num_layers in [1, 3, 5, 10]:\n",
    "    datamodule = LSTMDatasetModule(\n",
    "        target_column=\"label\",\n",
    "        text_column=\"preprocessed_text\",\n",
    "        batch_size=128,\n",
    "        model_path=CWD_PATH / \"glove_100_3_polish.txt\",\n",
    "        data_root=DATA_PATH\n",
    "    )\n",
    "    datamodule.setup()\n",
    "\n",
    "    model = LSTMModule(\n",
    "        model_path=CWD_PATH / \"glove_100_3_polish.txt\",\n",
    "        num_classes=2,\n",
    "        lr=1e-3,\n",
    "        class_weights=datamodule.get_class_weights(),\n",
    "        num_layers=num_layers\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=50,\n",
    "        accelerator=\"gpu\",\n",
    "        devices=\"auto\",\n",
    "        callbacks=[TQDMProgressBar(refresh_rate=2), ModelCheckpoint(\n",
    "            dirpath=\"checkpoints/\",\n",
    "            filename=\"{epoch}-{train_loss:.2f}\",\n",
    "            mode=\"min\",\n",
    "            monitor='train_loss',\n",
    "\n",
    "        )],\n",
    "        logger=TensorBoardLogger(save_dir=\"logs/\"),\n",
    "        log_every_n_steps=2,\n",
    "    )\n",
    "\n",
    "    tuner = Tuner(trainer)\n",
    "\n",
    "    tuner.lr_find(\n",
    "        model=model,\n",
    "        datamodule=datamodule,\n",
    "        method=\"fit\"\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    lstm_test_scores[num_layers] = trainer.test(model, datamodule=datamodule)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1bcf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T17:29:27.169120Z",
     "iopub.status.busy": "2023-12-28T17:29:27.168336Z",
     "iopub.status.idle": "2023-12-28T17:29:27.184649Z",
     "shell.execute_reply": "2023-12-28T17:29:27.183620Z",
     "shell.execute_reply.started": "2023-12-28T17:29:27.169089Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(lstm_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3e995f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50a857",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-28T16:30:28.828477Z",
     "iopub.status.idle": "2023-12-28T16:30:28.828830Z",
     "shell.execute_reply": "2023-12-28T16:30:28.828674Z",
     "shell.execute_reply.started": "2023-12-28T16:30:28.828656Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "from typing import Iterable, Iterator\n",
    "\n",
    "\n",
    "class FillingMaskDataGenerator:\n",
    "    def __init__(self) -> None:\n",
    "        model = BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "        tokenizer = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "        self.nlp = pipeline('fill-mask', model=model, tokenizer=tokenizer, top_k=3)\n",
    "\n",
    "    def get_for_single(self, masked_sentence: str, n: int = 3) -> Iterator[str]:\n",
    "        \"\"\"Create n examples with filled mask\n",
    "\n",
    "        Args:\n",
    "            masked_sentence (str): Sentence with '[MASK]' where to fill\n",
    "            n (int, optional): n examples. Defaults to 3.\n",
    "        \"\"\"\n",
    "        yield from [result[\"sequence\"] for result in self.nlp(masked_sentence)]\n",
    "    \n",
    "    def get_for_iterable(self, masked_sequences: Iterable[str], n: int = 3) -> Iterator[str]:\n",
    "        for masked_sequence in masked_sequences:\n",
    "            yield from self.get_for_single(masked_sentence=masked_sequence, n=n)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4209707,
     "sourceId": 7263284,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-28T21:22:56.013740",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
